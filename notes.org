#+title: Notes
#+LANGUAGE: ru
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper,fleqn,12pt]
#+LATEX_HEADER: \usepackage[lmargin=15mm, rmargin=15mm, tmargin=2cm, bmargin=2cm]{geometry}

* Тема

Выбор метода решения задачи одномерной оптимизации (равномерный поиск / золотое
сечение) для решения вспомогательной задачи градиентным методом наискорейшего
спуска

#+begin_src julia :session :exports none :results silent
using StatsPlots,Optim,CSV,DataFrames
gr()
f(x :: Vector{Float64}) = x[1]^2 + 4*x[2]^2 + sin(6*x[1] + 3*x[2]) + 3*x[1] + 2*x[2];
#+end_src

#+begin_src julia :results file graphics :file "figs/plot.png" :ouput-dir figs :exports both :cache no :session
x1 = range(-5,3, length=100);
x2 = range(-3,2, length=100);
vals = [f([x,y]) for y in x2, x in x1];
minim = Optim.minimizer(optimize(f,zeros(2), GradientDescent()));
# p1 = surface(x1,x2,vals, c=:curl, xlabel="x1", ylabel="x2", cam=(120,30));
# scatter!([minim[1]],[minim[2]],[f(minim)], label="min")
p2 = contour(x1,x2,vals,levels=25,fill=true, c=:curl, dpi = 300, xlabel="x1", ylabel="x2");
scatter!([minim[1]],[minim[2]], label="min");
# plot(p1,p2, size=(500,300), dpi=300)
savefig("figs/plot.png")
#+end_src

#+begin_src julia :session :results value :exports results
res = optimize(f, zeros(2), GradientDescent())
return (Optim.minimizer(res), Optim.minimum(res))
#+end_src

#+RESULTS:
: ([-1.2173845735465747, -0.2146730755196121], -3.410689361818459)

* Методы

#+name: plot
#+header: :var name = "ratio"
#+begin_src julia :session :exports code
df = CSV.read("build/res/" * name, DataFrame; header=["x","y"], delim=' ')
@df df plot(p2, :x, :y, labels = name)
savefig("figs/" * name * ".png")
#+end_src
** Золотое сечение

Рассмотрим $k$​-й шаг алгоритма. Интервал $[a_k,b_k]$
\[
\lambda_{k} = a_{k} + \alpha (b_{k} - a_{k}) \\ \mu_{k} = b_{k} - \alpha
(b_{k} - a_{k}) \\  \alpha = \frac{3 - \sqrt{5}}{2}
\]
Если $f(\lambda_k) > f(\mu_{k})$ на следующей итерации \([\lambda_{k}, b_{k}]\). При этом,
\(\lambda_{k+1} = \mu_{k}\) Иначе, \([a_{k},\mu_{k}]\), \(\mu_{k+1} = \lambda_{k}\)

#+call: plot[:results file graphics :file ratio.png :dir figs](name="ratio")
*** Оценка количества шагов
\([a_0,b_0]\) --- начальный интервал. \(\epsilon\) --- заданная точность. Рассмотрим
\(k\) шагов, \(i \in \NN, i \leq k\)
\[
  k: b_k - a_k \leq \epsilon
\]
\[
  b_k - a_k = (b_0 -a_0)\cdot(1 - \lambda)^{k}
\]
\[
  \epsilon \geq (b_0 - a_0)\cdot(1-\lambda)^{k}  \implies k \geq \log_{\frac{1}{1-\lambda}}(\frac{b_0-a_0}{\epsilon})
\]
На первом шаге функция вызывается 2 раза, на последующих 1. Т.о. всего \(k+1\)
вызовов функции.



** Равномерный поиск

#+call: plot[:results file graphics :file uniSearch.png :dir figs](name="uniSearch")
Рассмотрим \(k\)-й шаг алгоритма. Интервал \([a_k,b_k]\). Разобьём его на
подинтервалы точками \(x_i = a + ih, h = \frac{b-a}{n}, i = \overline{0,n}\).
\[
  \Let \min_{i} f(x_i) = f(x_j) \implies f(x_{j-1}) > f(x_j), f(x_{j+1}) > f(x_j)
\]
Функция унимодальна, значит \(x_{*} \in [x_{j-1},x_{j+1}]\). \(a_{k+1} = x_{j-1}, b_{k+1} = x_{j+1}\).
Продолжаем, пока не будет выполнено условие неопределённости: \(b - a = \epsilon\)

*** Оценка количества вызовов

\([a_0,b_0]\) --- начальный интервал. \(\epsilon\) --- заданная точность. Интервал
разбивается на \(n\) подинтервалов. Рассмотрим
\(k\) шагов, \(i \in \NN, i \leq k\)
\[
  k: b_k - a_k \leq \epsilon
\]
\[
  b_{i+1} - a_{i+1} = \frac{2}{n}(b_{i} - a_{i})
\]
\[
  b_k - a_k = \left( \frac{2}{n} \right)^{k}(b_0 - a_0)
\]
\[
  \epsilon \geq b_k - a_k \implies k \geq \log_{\frac{n}{2}} \left( \frac{b_{0} - a_{0}}{\epsilon} \right)
\]

На каждом шаге функция вызывается \(n-1\) раз, по количеству внутренних точек.
Таким образом, общее количество вызовов \(k\cdot(n-1)\)



